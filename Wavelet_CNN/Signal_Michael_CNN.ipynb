{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cd0b93a-236f-4bb1-827f-6481a497dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references('../../shared_data/training_mini/') \n",
    "# Importiere EKG-Dateien, zugehörige Diagnose, Sampling-Frequenz (Hz) und Name (meist fs=256 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5799da0-1280-4551-ae9a-731cbb85805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt\n",
    "import json\n",
    "import pywt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import numpy as np\n",
    "from wettbewerb import load_references, get_3montages, get_6montages\n",
    "import pywt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "number_montages = 3\n",
    "N_samples = 2000 # Number of samples per division\n",
    "# Decompose the wave\n",
    "wavelet = 'db4'\n",
    "scaler = StandardScaler()\n",
    "new_signal = []\n",
    "\n",
    "mont1_signal = []\n",
    "mont2_signal = []\n",
    "mont3_signal = []\n",
    "whole_mont = [mont1_signal,mont2_signal,mont3_signal]\n",
    "for i,_id in enumerate(ids):\n",
    "    \n",
    "    if number_montages == 6:\n",
    "        _montage, _montage_data, _is_missing = get_6montages(channels[i], data[i])\n",
    "    else:\n",
    "        _montage, _montage_data, _is_missing = get_3montages(channels[i], data[i])\n",
    "        \n",
    "    _fs = sampling_frequencies[i]\n",
    "    features_per_id = []\n",
    "\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        signal = _montage_data[j]\n",
    "        # Notch-Filter to compensate net frequency of 50 Hz\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
    "        # Bandpassfilter between 0.5Hz and 70Hz to filter out noise\n",
    "        signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "        # Defining number of divisions for signal\n",
    "        N_div = len(signal_filter)//N_samples\n",
    "        # Normalizing data\n",
    "        norm_montage_data = scaler.fit_transform(signal_filter.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    \n",
    "        for i in range(N_div):\n",
    "            montage_array = norm_montage_data[i*N_samples:(i+1)*N_samples]\n",
    "            whole_mont[j].append(montage_array)\n",
    "\n",
    "\n",
    "labels = []\n",
    "for i,_id in enumerate(ids):\n",
    "    if eeg_labels[i][0]:\n",
    "        onset = eeg_labels[i][1]\n",
    "        offset = eeg_labels[i][2]\n",
    "        sample_freq = sampling_frequencies[i]\n",
    "        total_time = len(data[i][1])/sample_freq\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            if (((total_time/N_div)*(num) <= onset) and ((total_time/N_div)*(num+1) > onset)) or (((total_time/N_div)*(num) >= onset) and ((total_time/N_div)*(num) < offset)):\n",
    "                labels.append([1])\n",
    "            else:\n",
    "                labels.append([0])\n",
    "    else:\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            labels.append([0])\n",
    "labels = np.reshape(labels, (1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814a75a1-62a5-41a3-b669-66aca2d00b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mont1_signal[8400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00f6a09-6600-46fa-ba96-c7eeabfe0a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8498"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f63ee4ba-0291-49e9-93c3-8d595644d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-51.61377435, -49.50124318, -47.74037637, ...,  43.29407623,\n",
       "         43.53920519,  43.78575418]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mont1_signal, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a20a2b4-8bd6-496e-b35a-5c54f6a7bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "# downsampling\n",
    "mont1_signal_smote, labels_smote = oversample.fit_resample(mont1_signal,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac0ca0d8-f068-4419-b5e0-3f9b02406e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-51.61377435, -49.50124318, -47.74037637, ...,  43.29407623,\n",
       "         43.53920519,  43.78575418]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mont1_signal_smote, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34328c86-f2e5-4233-8a71-3fa9d59b2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler()\n",
    "\n",
    "# Erstellen Sie eine Funktion, die das Resampling durchführt\n",
    "def resample_signal(signal, labels):\n",
    "    # Anwenden von RandomUnderSampler\n",
    "    signal_resampled, labels_resampled = undersample.fit_resample(signal, labels)\n",
    "    return signal_resampled, labels_resampled\n",
    "\n",
    "# Anwenden der Funktion auf jedes Signal\n",
    "mont1_signal_resampled, labels_resampled_1 = resample_signal(np.array(mont1_signal), labels)\n",
    "mont2_signal_resampled, labels_resampled_2 = resample_signal(np.array(mont2_signal), labels)\n",
    "mont3_signal_resampled, labels_resampled_3 = resample_signal(np.array(mont3_signal), labels)\n",
    "\n",
    "# Stellen Sie sicher, dass die Labels für alle Signale gleich sind, da sie das gleiche Set von Beispielen repräsentieren sollten\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_2)\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af082fd-6b71-451d-8c8b-f57d187e7f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d2996-5d72-4e15-bbf6-6344fd82d6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e5cb2-6ae3-467b-a771-eeaf6d8d4c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71f52e82-6f09-4d07-93b3-0093367ab40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\t Dateien wurden geladen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:41: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_18692/871857422.py:43: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train F1: 0.8926, Val F1: 0.9406\n",
      "Validation F1 Score increased (inf --> 0.940630). Saving model...\n",
      "Epoch 2: Train F1: 0.9371, Val F1: 0.9238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 3: Train F1: 0.9477, Val F1: 0.9235\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 4: Train F1: 0.9523, Val F1: 0.9649\n",
      "Validation F1 Score increased (0.940630 --> 0.964893). Saving model...\n",
      "Epoch 5: Train F1: 0.9579, Val F1: 0.9437\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 6: Train F1: 0.9667, Val F1: 0.8575\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 7: Train F1: 0.9717, Val F1: 0.9547\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 8: Train F1: 0.9718, Val F1: 0.9342\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 9: Train F1: 0.9760, Val F1: 0.9236\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from wettbewerb import load_references, get_3montages, get_6montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Daten laden und vorbereiten\n",
    "training_folder  = \"../../shared_data/training_mini\"\n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder)\n",
    "\n",
    "number_montages = 3\n",
    "N_samples = 2000 # Number of samples per division\n",
    "# Decompose the wave\n",
    "wavelet = 'db4'\n",
    "scaler = StandardScaler()\n",
    "new_signal = []\n",
    "\n",
    "mont1_signal = []\n",
    "mont2_signal = []\n",
    "mont3_signal = []\n",
    "whole_mont = [mont1_signal,mont2_signal,mont3_signal]\n",
    "for i,_id in enumerate(ids):\n",
    "    \n",
    "    if number_montages == 6:\n",
    "        _montage, _montage_data, _is_missing = get_6montages(channels[i], data[i])\n",
    "    else:\n",
    "        _montage, _montage_data, _is_missing = get_3montages(channels[i], data[i])\n",
    "        \n",
    "    _fs = sampling_frequencies[i]\n",
    "    features_per_id = []\n",
    "\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        signal = _montage_data[j]\n",
    "        # Notch-Filter to compensate net frequency of 50 Hz\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
    "        # Bandpassfilter between 0.5Hz and 70Hz to filter out noise\n",
    "        signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "        # Defining number of divisions for signal\n",
    "        N_div = len(signal_filter)//N_samples\n",
    "        # Normalizing data\n",
    "        norm_montage_data = scaler.fit_transform(signal_filter.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    \n",
    "        for i in range(N_div):\n",
    "            montage_array = norm_montage_data[i*N_samples:(i+1)*N_samples]\n",
    "            whole_mont[j].append(montage_array)\n",
    "\n",
    "\n",
    "\n",
    "labels = []\n",
    "for i,_id in enumerate(ids):\n",
    "    if eeg_labels[i][0]:\n",
    "        onset = eeg_labels[i][1]\n",
    "        offset = eeg_labels[i][2]\n",
    "        sample_freq = sampling_frequencies[i]\n",
    "        total_time = len(data[i][1])/sample_freq\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            if (((total_time/N_div)*(num) <= onset) and ((total_time/N_div)*(num+1) > onset)) or (((total_time/N_div)*(num) >= onset) and ((total_time/N_div)*(num) < offset)):\n",
    "                labels.append([1])\n",
    "            else:\n",
    "                labels.append([0])\n",
    "    else:\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            labels.append([0])\n",
    "labels = np.reshape(labels, (1,-1))[0]\n",
    "\n",
    "\n",
    "# Instanziierung von RandomUnderSampler\n",
    "undersample = RandomUnderSampler()\n",
    "\n",
    "# Erstellen Sie eine Funktion, die das Resampling durchführt\n",
    "def resample_signal(signal, labels):\n",
    "    # Anwenden von RandomUnderSampler\n",
    "    signal_resampled, labels_resampled = undersample.fit_resample(signal, labels)\n",
    "    return signal_resampled, labels_resampled\n",
    "\n",
    "# Anwenden der Funktion auf jedes Signal\n",
    "mont1_signal_resampled, labels_resampled_1 = resample_signal(np.array(mont1_signal), labels)\n",
    "mont2_signal_resampled, labels_resampled_2 = resample_signal(np.array(mont2_signal), labels)\n",
    "mont3_signal_resampled, labels_resampled_3 = resample_signal(np.array(mont3_signal), labels)\n",
    "\n",
    "# Stellen Sie sicher, dass die Labels für alle Signale gleich sind, da sie das gleiche Set von Beispielen repräsentieren sollten\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_2)\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_3)\n",
    "\n",
    "labels_resampled = labels_resampled_1\n",
    "\n",
    "whole_mont_resampled = [mont1_signal_resampled,mont2_signal_resampled,mont3_signal_resampled]\n",
    "\n",
    "\n",
    "\n",
    "whole_mont_resampled_np = np.array(whole_mont_resampled)\n",
    "\n",
    "# Dataset-Klasse\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, whole_mont_resampled_np, labels_resampled):\n",
    "        # Hier wird angenommen, dass `data` bereits ein Tensor ist. Wenn nicht, sollten Sie `data` in einen Tensor umwandeln.\n",
    "        self.data = torch.from_numpy(whole_mont_resampled_np).float()\n",
    "        self.labels = torch.from_numpy(np.array(labels_resampled)).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[1]  # Anzahl der Beispiele entspricht nun dem zweiten Dimension\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Für jedes Beispiel: Holt das idx-te Beispiel über alle Kanäle\n",
    "        # Keine Notwendigkeit, permute oder unsqueeze zu verwenden\n",
    "        sample = self.data[:, idx, :]  # Behält die Form [Kanäle, Länge] bei\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "# Initialisierung des EEGDataset mit vorbereiteten Daten und Labels\n",
    "eeg_dataset = EEGDataset(whole_mont_resampled_np, labels_resampled)\n",
    "\n",
    "\n",
    "\n",
    "# CNN-Modell\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, seq_length):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm1d(num_features=6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(6, 16, 5),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Anpassung für die Berechnung der Größe des linearen Layers\n",
    "        linear_input_size = self._get_conv_output(seq_length)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(linear_input_size, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            input = torch.zeros(1, 3, shape)\n",
    "            output = self.classifier(input)\n",
    "            return output.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Teilen Sie Ihre Daten in Trainings- und Validierungssets\n",
    "dataset_size = len(eeg_dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(eeg_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=True, delta=0.0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.f1_score_max = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, f1_score, model):\n",
    "        score = f1_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, f1_score, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation F1 Score increased ({self.f1_score_max:.6f} --> {f1_score:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.f1_score_max = f1_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(num_classes=2, seq_length=2000).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path='checkpoint.pt')\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_predictions.extend(predictions.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_f1 = f1_score(train_targets, train_predictions, average='macro')\n",
    "\n",
    "        val_losses = []\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "        early_stopping(val_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=100, device=device)\n",
    "\n",
    "# Nach dem Training das beste Modell laden\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1420dc08-3a39-47a5-8a2d-f4dc994029bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten Typ: <class 'list'>\n",
      "Länge der Daten: 3\n",
      "Typ des ersten Elements: <class 'list'>\n",
      "Form des ersten Elements (falls NumPy Array): (8498, 2000)\n",
      "Labels Typ: <class 'numpy.ndarray'>\n",
      "Labels Form: (8498,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Daten Typ:\", type(whole_mont))  # Überprüft den Typ der Variable\n",
    "if isinstance(whole_mont, np.ndarray):\n",
    "    print(\"Daten Form:\", whole_mont.shape)\n",
    "else:\n",
    "    # Für Listen oder andere Datentypen, die keine .shape-Attribut haben\n",
    "    print(\"Länge der Daten:\", len(whole_mont))\n",
    "    if len(whole_mont) > 0:\n",
    "        print(\"Typ des ersten Elements:\", type(whole_mont[0]))\n",
    "        print(\"Form des ersten Elements (falls NumPy Array):\", np.array(whole_mont[0]).shape)\n",
    "\n",
    "print(\"Labels Typ:\", type(labels))\n",
    "print(\"Labels Form:\", np.array(labels).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1921754-fecf-4253-a01e-2e043e687320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 8498, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(type(whole_mont_np))\n",
    "print(whole_mont_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737ab0cc-7b8c-4187-9969-f41f18fd1177",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_smote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mlabels_smote\u001b[49m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_smote' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47945b25-cf65-4bf6-8ec7-1570ad4a8bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25494, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(flattened_data_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "862e3aec-521a-438d-b434-cca684b1a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_mont_np = np.array(whole_mont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ee049b-e4a7-4d39-ae3d-1a7d68cb8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8498, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(whole_mont_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d632b6-d5cb-430b-ae79-d6250fa14c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8498,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30606ae0-32bc-448e-ab6b-77d18d6f05af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
