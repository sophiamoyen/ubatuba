{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e46637-2d5e-4614-a670-9e9825691f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=1.8.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: mne>=1.3.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: ruptures>=1.1.7 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.1.7)\n",
      "Requirement already satisfied: mysql-connector-python>=8.0.26 in /home/jupyter-wki_team_6/.local/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.2.0)\n",
      "Requirement already satisfied: joblib>=1.2 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (4.33.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (4.65.0)\n",
      "Requirement already satisfied: decorator in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: protobuf<=4.21.12,>=4.21.1 in /home/jupyter-wki_team_6/.local/lib/python3.8/site-packages (from mysql-connector-python>=8.0.26->-r requirements.txt (line 7)) (4.21.12)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from jinja2->mne>=1.3.1->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abcba99-e827-4312-8be5-e865dd09e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dcdbdd-bf21-48d9-9cf3-0f656a8bc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = \"../../shared_data/training_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbd4504-c960-456b-a85d-3a37997f41c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ae66e0-07e7-4249-aa02-80cddac93bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d99089-098c-418c-8962-05c562ad36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 60000  # Angenommene feste Länge für jede Zeitreihe\n",
    "\n",
    "X_processed = []\n",
    "\n",
    "for montage_data in X:\n",
    "    current_length = montage_data.shape[2]  # Die aktuelle Länge der Zeitreihe\n",
    "    if current_length < fixed_length:\n",
    "        # Auffüllen kürzerer Zeitreihen\n",
    "        padding_length = fixed_length - current_length\n",
    "        padding = np.zeros((montage_data.shape[0], montage_data.shape[1], padding_length))\n",
    "        montage_data_padded = np.concatenate((montage_data, padding), axis=2)\n",
    "    else:\n",
    "        # Abschneiden, wenn die Aufnahme zu lang ist\n",
    "        montage_data_padded = montage_data[:, :, :fixed_length]\n",
    "\n",
    "    X_processed.append(montage_data_padded)\n",
    "\n",
    "# Umwandeln in NumPy-Array und dann in PyTorch-Tensor\n",
    "X_array = np.array(X_processed, dtype=np.float32)\n",
    "X_tensor = torch.tensor(X_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a427ae3-d99c-473c-8b2b-58d79d4ae9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 60000  # Angenommene feste Länge für jede Zeitreihe\n",
    "\n",
    "X_processed = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    _, montage_data, _ = get_3montages(channels[i], data[i])\n",
    "    current_length = montage_data.shape[1]\n",
    "\n",
    "    if current_length < fixed_length:\n",
    "        # Auffüllen kürzerer Zeitreihen\n",
    "        padding = np.zeros((montage_data.shape[0], fixed_length - current_length))\n",
    "        montage_data_padded = np.concatenate((montage_data, padding), axis=1)\n",
    "    else:\n",
    "        # Abschneiden, wenn die Aufnahme zu lang ist\n",
    "        montage_data_padded = montage_data[:, :fixed_length]\n",
    "\n",
    "    montage_data_reshaped = montage_data_padded.reshape(1, montage_data_padded.shape[0], montage_data_padded.shape[1])\n",
    "    X_processed.append(montage_data_reshaped)\n",
    "\n",
    "X_tensor = torch.tensor(np.array(X_processed), dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93243232-a66e-43c8-9d9c-38b3f0358b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form der Feature-Daten (X_tensor): torch.Size([100, 1, 3, 60000])\n",
      "Form der Label-Daten (Y_tensor): torch.Size([100])\n",
      "Einige Beispieldaten:\n",
      " tensor([[[[-5.6763e-05, -5.1575e-05, -5.7373e-05,  ..., -1.1932e-03,\n",
      "           -1.1874e-03, -1.1691e-03],\n",
      "          [ 7.0190e-06,  3.3569e-05,  4.1504e-05,  ..., -5.7068e-05,\n",
      "           -4.4556e-05,  1.8311e-06],\n",
      "          [-5.4932e-06, -2.2888e-05, -1.5564e-05,  ..., -3.7842e-05,\n",
      "           -6.3171e-05, -8.3008e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6926e-05,  4.8523e-05,  4.6387e-05,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-5.4932e-06,  3.3264e-05,  3.9673e-05,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.7466e-06, -3.5706e-05, -3.6316e-05,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.1128e-05, -3.1433e-05, -3.6621e-05,  ...,  8.1177e-05,\n",
      "            9.1858e-05,  9.1248e-05],\n",
      "          [ 2.8076e-05,  5.0659e-05,  2.0447e-05,  ...,  7.4463e-05,\n",
      "            1.1688e-04,  1.4008e-04],\n",
      "          [ 2.2980e-04,  2.2491e-04,  2.4811e-04,  ...,  1.8616e-05,\n",
      "           -9.7656e-06, -1.6785e-05]]],\n",
      "\n",
      "\n",
      "        [[[-3.9063e-05, -4.0894e-05, -4.3640e-05,  ..., -3.9673e-06,\n",
      "           -5.7983e-06, -7.3242e-06],\n",
      "          [-3.9673e-06, -5.1880e-06, -5.7983e-06,  ...,  5.7983e-06,\n",
      "            6.4087e-06,  7.3242e-06],\n",
      "          [ 6.1035e-07,  9.1553e-07, -3.6621e-06,  ..., -1.0986e-05,\n",
      "           -1.4038e-05, -1.3428e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0986e-05,  1.2512e-05,  1.4343e-05,  ..., -1.4648e-05,\n",
      "           -1.4648e-05, -1.6174e-05],\n",
      "          [ 1.0681e-05,  1.0071e-05,  6.4087e-06,  ..., -5.7983e-06,\n",
      "           -5.4932e-06, -5.4932e-06],\n",
      "          [-1.4954e-05, -1.1902e-05, -9.1553e-06,  ..., -4.0588e-05,\n",
      "           -3.2959e-05, -3.2654e-05]]]])\n",
      "Maximaler Wert in den Daten: tensor(0.0048)\n",
      "Minimaler Wert in den Daten: tensor(-0.0052)\n",
      "Durchschnittlicher Wert in den Daten: tensor(2.7823e-06)\n",
      "Verteilung der Klassen in Y_tensor: {0: 64, 1: 36}\n"
     ]
    }
   ],
   "source": [
    "print(\"Form der Feature-Daten (X_tensor):\", X_tensor.shape)\n",
    "print(\"Form der Label-Daten (Y_tensor):\", Y_tensor.shape)\n",
    "\n",
    "# Anzeigen einiger Beispieldaten\n",
    "print(\"Einige Beispieldaten:\\n\", X_tensor[0:5])\n",
    "\n",
    "# Statistiken der Daten\n",
    "print(\"Maximaler Wert in den Daten:\", torch.max(X_tensor))\n",
    "print(\"Minimaler Wert in den Daten:\", torch.min(X_tensor))\n",
    "print(\"Durchschnittlicher Wert in den Daten:\", torch.mean(X_tensor.float()))\n",
    "\n",
    "# Verteilung der Klassen\n",
    "unique, counts = torch.unique(Y_tensor, return_counts=True)\n",
    "print(\"Verteilung der Klassen in Y_tensor:\", dict(zip(unique.tolist(), counts.tolist())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "922b3063-1bef-4d00-bbe7-b23cfa3b0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definieren Sie Ihr CNN-Modell\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm1d(num_features=6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(6, 16, 5),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "        )\n",
    "        \n",
    "        # Berechnen der Größe für die erste vollverbundene Schicht\n",
    "        with torch.no_grad():\n",
    "            self._to_linear = None\n",
    "            self._forward_conv(torch.zeros(1, *input_size))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 2),  # 2 Ausgabeneuronen für binäre Klassifikation\n",
    "        )\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.classifier(x)\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x.view(1, -1).size(1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(-1, self._to_linear)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Erstellen Sie eine Instanz des Modells\n",
    "input_size = (1, 60000)  # Angenommen, die Länge der Zeitreihe ist 60000\n",
    "model = CNN(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0acfcfce-dcb9-4083-81d6-7f21dcb37efc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [32, 1, 3, 60000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Vorwärtsdurchlauf\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Berechnen Sie den Verlust\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_linear)  \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mCNN._forward_conv\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_conv\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_linear \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_linear \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:302\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:298\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    296\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    297\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [32, 1, 3, 60000]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definieren Sie die Verlustfunktion und den Optimierer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Definieren Sie die Anzahl der Epochen und den Batch-Size\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Erstellen Sie ein DataLoader für die Trainingsdaten\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Trainings-Schleife\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Setzen des Modells in den Trainingsmodus\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Nullen Sie die Gradienten\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Vorwärtsdurchlauf\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Berechnen Sie den Verlust\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Rückwärtsdurchlauf und Optimierung\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Durchschnittlicher Verlust pro Epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_loss:.4f}')\n",
    "\n",
    "print('Training abgeschlossen.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e63516-db37-4775-b2a6-2dfa00e64cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
