{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac3032a-c2fa-4e06-b071-180c6894cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from wettbewerb import load_references, get_3montages, get_6montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c77e341-3dc0-4d4d-b231-619de9c98f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden und vorbereiten\n",
    "training_folder  = \"../../test_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f85bf0-9395-44b3-8276-b7ca26760899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4070e576-0e0c-4189-a22b-bcf34aa577a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_montages = 3\n",
    "N_samples = 2000 # Number of samples per division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0717125-dc58-4eb4-807f-883ba034ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1536), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (1691) is longer than the signal (1280), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2400), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:23: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
      "/tmp/ipykernel_2827632/1170032774.py:25: RuntimeWarning: filter_length (2641) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Decompose the wave\n",
    "wavelet = 'db4'\n",
    "scaler = StandardScaler()\n",
    "new_signal = []\n",
    "\n",
    "mont1_signal = []\n",
    "mont2_signal = []\n",
    "mont3_signal = []\n",
    "whole_mont = [mont1_signal,mont2_signal,mont3_signal]\n",
    "for i,_id in enumerate(ids):\n",
    "    \n",
    "    if number_montages == 6:\n",
    "        _montage, _montage_data, _is_missing = get_6montages(channels[i], data[i])\n",
    "    else:\n",
    "        _montage, _montage_data, _is_missing = get_3montages(channels[i], data[i])\n",
    "        \n",
    "    _fs = sampling_frequencies[i]\n",
    "    features_per_id = []\n",
    "\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        signal = _montage_data[j]\n",
    "        # Notch-Filter to compensate net frequency of 50 Hz\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
    "        # Bandpassfilter between 0.5Hz and 70Hz to filter out noise\n",
    "        signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "        # Defining number of divisions for signal\n",
    "        N_div = len(signal_filter)//N_samples\n",
    "        # Normalizing data\n",
    "        norm_montage_data = scaler.fit_transform(signal_filter.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    \n",
    "        for i in range(N_div):\n",
    "            montage_array = norm_montage_data[i*N_samples:(i+1)*N_samples]\n",
    "            whole_mont[j].append(montage_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39d17e8-b664-4eaa-aba6-b9ba94660467",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i,_id in enumerate(ids):\n",
    "    if eeg_labels[i][0]:\n",
    "        onset = eeg_labels[i][1]\n",
    "        offset = eeg_labels[i][2]\n",
    "        sample_freq = sampling_frequencies[i]\n",
    "        total_time = len(data[i][1])/sample_freq\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            if (((total_time/N_div)*(num) <= onset) and ((total_time/N_div)*(num+1) > onset)) or (((total_time/N_div)*(num) >= onset) and ((total_time/N_div)*(num) < offset)):\n",
    "                labels.append([1])\n",
    "            else:\n",
    "                labels.append([0])\n",
    "    else:\n",
    "        N_div = len(data[i][1])//N_samples\n",
    "        for num in range(N_div):\n",
    "            labels.append([0])\n",
    "labels = np.reshape(labels, (1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e0ecec-1c25-4c72-9a27-d5079e86ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziierung von RandomUnderSampler\n",
    "undersample = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4586bbdf-0c26-47e9-8282-d547d94730ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie eine Funktion, die das Resampling durchführt\n",
    "def resample_signal(signal, labels):\n",
    "    # Anwenden von RandomUnderSampler\n",
    "    signal_resampled, labels_resampled = undersample.fit_resample(signal, labels)\n",
    "    return signal_resampled, labels_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7fa345-4846-4ef7-8df7-5c96801a6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwenden der Funktion auf jedes Signal\n",
    "mont1_signal_resampled, labels_resampled_1 = resample_signal(np.array(mont1_signal), labels)\n",
    "mont2_signal_resampled, labels_resampled_2 = resample_signal(np.array(mont2_signal), labels)\n",
    "mont3_signal_resampled, labels_resampled_3 = resample_signal(np.array(mont3_signal), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d38fd83d-425b-473c-8edc-47ba7de1ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stellen Sie sicher, dass die Labels für alle Signale gleich sind, da sie das gleiche Set von Beispielen repräsentieren sollten\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_2)\n",
    "assert np.array_equal(labels_resampled_1, labels_resampled_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04969f92-5a3a-45ce-a3bd-fa2adf8f207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_resampled = labels_resampled_1\n",
    "whole_mont_resampled = [mont1_signal_resampled,mont2_signal_resampled,mont3_signal_resampled]\n",
    "whole_mont_resampled_np = np.array(whole_mont_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ea6e07-e391-4770-bd0e-9eb349dd4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_resampled = labels\n",
    "whole_mont_resampled_np = np.array(whole_mont)\n",
    "\n",
    "# Dataset-Klasse\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, whole_mont_resampled_np, labels_resampled):\n",
    "        # Hier wird angenommen, dass `data` bereits ein Tensor ist. Wenn nicht, sollten Sie `data` in einen Tensor umwandeln.\n",
    "        self.data = torch.from_numpy(whole_mont_resampled_np).float()\n",
    "        self.labels = torch.from_numpy(np.array(labels_resampled)).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[1]  # Anzahl der Beispiele entspricht nun dem zweiten Dimension\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Für jedes Beispiel: Holt das idx-te Beispiel über alle Kanäle\n",
    "        # Keine Notwendigkeit, permute oder unsqueeze zu verwenden\n",
    "        sample = self.data[:, idx, :]  # Behält die Form [Kanäle, Länge] bei\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d656be-bd21-42aa-a022-97d478073e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung des EEGDataset mit vorbereiteten Daten und Labels\n",
    "eeg_dataset = EEGDataset(whole_mont_resampled_np, labels_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de54f9b2-48a0-40c5-abba-b9e179b5d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-Modell\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, seq_length):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm1d(num_features=6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(6, 16, 5),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Anpassung für die Berechnung der Größe des linearen Layers\n",
    "        linear_input_size = self._get_conv_output(seq_length)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(linear_input_size, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            input = torch.zeros(1, 3, shape)\n",
    "            output = self.classifier(input)\n",
    "            return output.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76049b3-b082-4f90-9a88-7eb84b397a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teilen Sie Ihre Daten in Trainings- und Validierungssets\n",
    "dataset_size = len(eeg_dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(eeg_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314cd65e-f27f-46ec-9747-5e2054669938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab2bd51f-b0bd-44c6-9535-d41e606cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=True, delta=0.0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.f1_score_max = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, f1_score, model):\n",
    "        score = f1_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, f1_score, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation F1 Score increased ({self.f1_score_max:.6f} --> {f1_score:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.f1_score_max = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d92ccb3-f84d-4fab-bf33-b296279765dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590ba27a-7983-4122-b680-24bb2581efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes=2, seq_length=2000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a5f931-5707-4b77-9a0f-d66e0cab4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a846124a-33df-436c-9913-5ca5210ef9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path='checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edddbdca-6fda-4bfb-a1f5-41f73346a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_predictions.extend(predictions.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_f1 = f1_score(train_targets, train_predictions, average='macro')\n",
    "\n",
    "        val_losses = []\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "        early_stopping(val_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55aae011-a8f6-47af-8291-dd7aef7443ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train F1: 0.8849, Val F1: 0.8862\n",
      "Validation F1 Score increased (inf --> 0.886174). Saving model...\n",
      "Epoch 2: Train F1: 0.9584, Val F1: 0.9576\n",
      "Validation F1 Score increased (0.886174 --> 0.957597). Saving model...\n",
      "Epoch 3: Train F1: 0.9770, Val F1: 0.9859\n",
      "Validation F1 Score increased (0.957597 --> 0.985861). Saving model...\n",
      "Epoch 4: Train F1: 0.9894, Val F1: 0.9788\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 5: Train F1: 0.9929, Val F1: 0.9682\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 6: Train F1: 0.9947, Val F1: 0.9682\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 7: Train F1: 0.9894, Val F1: 0.9788\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 8: Train F1: 0.9832, Val F1: 0.9858\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ad50a3-57d1-4618-b4db-b6e86969a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nach dem Training das beste Modell laden\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6ca4d8-cd58-4707-bdf5-58044c36e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1412, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(whole_mont_resampled_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafb289-42cb-4e28-95ed-3c23aec8f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train F1: 0.5205, Precision: 0.7381, Recall: 0.5186\n",
      "Epoch 1: Val F1: 0.6347, Precision: 0.8376, Recall: 0.5915\n",
      "Validation F1 Score increased (inf --> 0.634684). Saving model...\n",
      "Epoch 2: Train F1: 0.6264, Precision: 0.8003, Recall: 0.5870\n",
      "Epoch 2: Val F1: 0.6712, Precision: 0.8599, Recall: 0.6192\n",
      "Validation F1 Score increased (0.634684 --> 0.671196). Saving model...\n",
      "Epoch 3: Train F1: 0.6846, Precision: 0.8403, Recall: 0.6329\n",
      "Epoch 3: Val F1: 0.6911, Precision: 0.7821, Recall: 0.6487\n",
      "Validation F1 Score increased (0.671196 --> 0.691107). Saving model...\n",
      "Epoch 4: Train F1: 0.7127, Precision: 0.8413, Recall: 0.6598\n",
      "Epoch 4: Val F1: 0.6260, Precision: 0.9052, Recall: 0.5827\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Epoch 5: Train F1: 0.7417, Precision: 0.8564, Recall: 0.6875\n",
      "Epoch 5: Val F1: 0.6241, Precision: 0.9282, Recall: 0.5808\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Epoch 6: Train F1: 0.7662, Precision: 0.8648, Recall: 0.7134\n",
      "Epoch 6: Val F1: 0.6961, Precision: 0.8027, Recall: 0.6498\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Epoch 7: Train F1: 0.7857, Precision: 0.8685, Recall: 0.7364\n",
      "Epoch 7: Val F1: 0.6931, Precision: 0.7294, Recall: 0.6683\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Epoch 8: Train F1: 0.8042, Precision: 0.8809, Recall: 0.7558\n",
      "Epoch 8: Val F1: 0.6967, Precision: 0.8023, Recall: 0.6505\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Epoch 9: Train F1: 0.8194, Precision: 0.8837, Recall: 0.7757\n",
      "Epoch 9: Val F1: 0.7068, Precision: 0.7815, Recall: 0.6668\n",
      "Validation F1 Score increased (0.691107 --> 0.706815). Saving model...\n",
      "Epoch 10: Train F1: 0.8276, Precision: 0.8894, Recall: 0.7846\n",
      "Epoch 10: Val F1: 0.6879, Precision: 0.7992, Recall: 0.6419\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Epoch 11: Train F1: 0.8423, Precision: 0.8936, Recall: 0.8042\n",
      "Epoch 11: Val F1: 0.6920, Precision: 0.8421, Recall: 0.6394\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Epoch 12: Train F1: 0.8470, Precision: 0.8948, Recall: 0.8107\n",
      "Epoch 12: Val F1: 0.7031, Precision: 0.7658, Recall: 0.6672\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Epoch 13: Train F1: 0.8599, Precision: 0.9031, Recall: 0.8262\n",
      "Epoch 13: Val F1: 0.7053, Precision: 0.7432, Recall: 0.6791\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Epoch 14: Train F1: 0.8585, Precision: 0.9032, Recall: 0.8238\n",
      "Epoch 14: Val F1: 0.6369, Precision: 0.7697, Recall: 0.5978\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Epoch 15: Train F1: 0.8615, Precision: 0.9018, Recall: 0.8295\n",
      "Epoch 15: Val F1: 0.6154, Precision: 0.8525, Recall: 0.5768\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Epoch 16: Train F1: 0.8651, Precision: 0.9073, Recall: 0.8318\n",
      "Epoch 16: Val F1: 0.6557, Precision: 0.7637, Recall: 0.6157\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Epoch 17: Train F1: 0.8663, Precision: 0.9023, Recall: 0.8370\n",
      "Epoch 17: Val F1: 0.7023, Precision: 0.7229, Recall: 0.6859\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Epoch 18: Train F1: 0.8682, Precision: 0.9041, Recall: 0.8390\n",
      "Epoch 18: Val F1: 0.7093, Precision: 0.7101, Recall: 0.7084\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Epoch 19: Train F1: 0.8735, Precision: 0.9082, Recall: 0.8450\n",
      "Epoch 19: Val F1: 0.6856, Precision: 0.6968, Recall: 0.6759\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Epoch 20: Train F1: 0.8775, Precision: 0.9106, Recall: 0.8500\n",
      "Epoch 20: Val F1: 0.6491, Precision: 0.7364, Recall: 0.6135\n",
      "EarlyStopping counter: 11 out of 40\n",
      "Epoch 21: Train F1: 0.8796, Precision: 0.9155, Recall: 0.8501\n",
      "Epoch 21: Val F1: 0.7008, Precision: 0.6850, Recall: 0.7206\n",
      "EarlyStopping counter: 12 out of 40\n",
      "Epoch 22: Train F1: 0.8798, Precision: 0.9112, Recall: 0.8534\n",
      "Epoch 22: Val F1: 0.6997, Precision: 0.7622, Recall: 0.6641\n",
      "EarlyStopping counter: 13 out of 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# Ersetze die folgende Zeile durch den tatsächlichen Import deiner CNN-Klasse\n",
    "# from your_model_file import CNN\n",
    "# Ersetze die folgende Zeile durch den tatsächlichen Import deiner EarlyStopping-Klasse\n",
    "# from your_early_stopping_file import EarlyStopping\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=True, delta=0.0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.f1_score_max = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, f1_score, model):\n",
    "        score = f1_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, f1_score, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation F1 Score increased ({self.f1_score_max:.6f} --> {f1_score:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.f1_score_max = f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(num_classes=2, seq_length=2000).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "early_stopping = EarlyStopping(patience=40, verbose=True, delta=0.01, path='checkpoint.pt')\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_predictions.extend(predictions.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_f1 = f1_score(train_targets, train_predictions, average='macro')\n",
    "        train_precision = precision_score(train_targets, train_predictions, average='macro')\n",
    "        train_recall = recall_score(train_targets, train_predictions, average='macro')\n",
    "\n",
    "        val_losses = []\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
    "        val_precision = precision_score(val_targets, val_predictions, average='macro')\n",
    "        val_recall = recall_score(val_targets, val_predictions, average='macro')\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train F1: {train_f1:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}')\n",
    "        print(f'Epoch {epoch+1}: Val F1: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}')\n",
    "\n",
    "        early_stopping(val_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=100, device=device)\n",
    "# Nach dem Training das beste Modell laden\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97468d6a-4fb3-4df5-8866-7c8f2f13d8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
