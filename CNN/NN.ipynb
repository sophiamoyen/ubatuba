{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511ce21c-0ca3-46a1-b3a8-e29ce75e247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=1.8.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: mne>=1.3.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: ruptures>=1.1.7 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.1.7)\n",
      "Requirement already satisfied: mysql-connector-python>=8.0.26 in /home/jupyter-wki_team_6/.local/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.2.0)\n",
      "Requirement already satisfied: joblib>=1.2 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (4.33.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (9.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.3.0->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (4.65.0)\n",
      "Requirement already satisfied: decorator in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from mne>=1.3.1->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: protobuf<=4.21.12,>=4.21.1 in /home/jupyter-wki_team_6/.local/lib/python3.8/site-packages (from mysql-connector-python>=8.0.26->-r requirements.txt (line 7)) (4.21.12)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from jinja2->mne>=1.3.1->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/tljh/user/envs/pytorch/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.3.1->-r requirements.txt (line 5)) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb123175-ca33-4feb-8bfc-f632f8c9de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79e06304-399d-4464-9e32-fc8dd8c12160",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = \"../../shared_data/training_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f4e750-c88d-4b30-8d62-bb3896e3a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44ad2f2-c72a-4afa-93dc-a92289b4b210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionen der formatierten Daten: (100, 3, 400)\n",
      "Die Daten haben das erwartete Format.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Angenommen, Sie haben Ihre Daten bereits geladen:\n",
    "# ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder)\n",
    "\n",
    "# Konvertieren der EEG-Daten in das erforderliche Format\n",
    "def prepare_data(data, channels, sampling_frequencies, time_steps=400):\n",
    "    num_records = len(data)\n",
    "    formatted_data = np.empty((num_records, 3, time_steps)) # [Anzahl der Beispiele, 3 Kanäle, Zeitpunkte]\n",
    "\n",
    "    for i in range(num_records):\n",
    "        _fs = sampling_frequencies[i]\n",
    "        montages, montage_data, _ = get_3montages(channels[i], data[i])\n",
    "\n",
    "        # Filter für jedes Montage anwenden\n",
    "        for j in range(montage_data.shape[0]):\n",
    "            signal = montage_data[j, :]\n",
    "            # Anwenden des Notch-Filters\n",
    "            signal_notch = mne.filter.notch_filter(x=signal, Fs=_fs, freqs=np.array([50., 100.]), n_jobs=2, verbose=False)\n",
    "            # Anwenden des Bandpassfilters\n",
    "            signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=_fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "            montage_data[j, :] = signal_filter\n",
    "\n",
    "        # Skalieren oder Auffüllen der Daten auf die gewünschte Länge\n",
    "        montage_data_resized = montage_data[:, :time_steps] if montage_data.shape[1] > time_steps else np.pad(montage_data, ((0,0), (0, time_steps - montage_data.shape[1])), 'constant')\n",
    "        formatted_data[i] = montage_data_resized\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "# Vorbereiten der Daten mit Filtern\n",
    "formatted_data = prepare_data(data, channels, sampling_frequencies)\n",
    "\n",
    "# Überprüfen der Dimensionen der formatierten Daten\n",
    "print(\"Dimensionen der formatierten Daten:\", formatted_data.shape)\n",
    "\n",
    "# Stellen Sie sicher, dass die Dimensionen [num_records, 3, time_steps] sind\n",
    "expected_shape = (len(data), 3, 400)  # 400 ist ein Beispiel für time_steps\n",
    "if formatted_data.shape == expected_shape:\n",
    "    print(\"Die Daten haben das erwartete Format.\")\n",
    "else:\n",
    "    print(f\"Unerwartetes Format. Erwartet: {expected_shape}, Erhalten: {formatted_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0086d286-ee43-411c-9677-7f88508e65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data).float()  # Konvertieren zu torch.Tensor\n",
    "        self.labels = torch.from_numpy(np.array(labels)).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Erstellen des Datasets\n",
    "eeg_dataset = EEGDataset(formatted_data, np.array([label[0] for label in eeg_labels]))  # Hier nehmen wir nur den Teil \"seizure_present\" als Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa8aa2b-6c35-46d9-90ad-1da183187efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, seq_length):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm1d(num_features=6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(6, 16, 5),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Anpassung für die Berechnung der Größe des linearen Layers\n",
    "        linear_input_size = self._get_conv_output(seq_length)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(linear_input_size, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            input = torch.zeros(1, 3, shape)\n",
    "            output = self.classifier(input)\n",
    "            return output.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9d70ce0-517e-40e4-a918-032f43e9cc00",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Definieren Sie Ihr Modell, Verlustfunktion und Optimierer\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Angenommen, Ihre EEGDataset Klasse ist bereits definiert und instanziiert als `eeg_dataset`\n",
    "\n",
    "# Teilen Sie Ihre Daten in Trainings- und Validierungssets\n",
    "dataset_size = len(eeg_dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(eeg_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Geräteeinstellungen (nutzt GPU, falls verfügbar, sonst CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Definieren Sie Ihr Modell, Verlustfunktion und Optimierer\n",
    "model = CNN(num_classes=2, seq_length=400).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    predictions, targets = [], []\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        predictions.extend(predicted.view(-1).cpu().numpy())\n",
    "        targets.extend(labels.view(-1).cpu().numpy())\n",
    "        \n",
    "    f1 = f1_score(targets, predictions, average='macro')\n",
    "    return total_loss / total_samples, total_correct / total_samples, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    predictions, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            predictions.extend(predicted.view(-1).cpu().numpy())\n",
    "            targets.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(targets, predictions, average='macro')\n",
    "    return total_loss / total_samples, total_correct / total_samples, f1\n",
    "\n",
    "# Trainingszyklus\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, val_f1 = validate(model, val_dataloader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "279ece50-fdb8-48bf-8db5-f2ebedb345f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 400])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b079f20b-ef6a-4488-a5f9-2e0d8a46fc00",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Modell auf das gewählte Gerät übertragen\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Hyperparameter\u001b[39;00m\n\u001b[1;32m     13\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Geräteeinstellungen (nutzt GPU, falls verfügbar)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Modell auf das gewählte Gerät übertragen\n",
    "model = model.to(device)\n",
    "\n",
    "# Hyperparameter\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Loss-Funktion und Optimierer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "# DataLoader für Training und Validierung (ersetzen Sie diese mit Ihren eigenen Datensätzen)\n",
    "# train_dataset = ...\n",
    "# val_dataset = ...\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Validierungssets\n",
    "train_size = int((1 - validation_split) * len(eeg_dataset))\n",
    "val_size = len(eeg_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(eeg_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Trainings- und Validierungsschleife\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_targets = []\n",
    "    train_predictions = []\n",
    "\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Vorwärtsdurchlauf\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Rückwärtsdurchlauf und Optimierung\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Speichern von Vorhersagen und Zielen für die F1-Berechnung\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_targets.extend(targets.cpu().numpy())\n",
    "        train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    train_f1 = f1_score(train_targets, train_predictions, average='macro')\n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "    # Validierung\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_targets = []\n",
    "    val_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_targets.extend(targets.cpu().numpy())\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}, Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# Weiterer Code für die Auswertung oder Speicherung des Modells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b89c39-e628-4535-8d99-002d71563f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7489ada-0d99-4c84-b938-96c8782902e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3720fd4-f975-4564-9179-d12b97b2974f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488ff85b-b005-425f-8748-fd6f00856a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datentyp von 'data': <class 'list'>\n",
      "Struktur der EEG-Daten: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Datentyp von 'data':\", type(data))\n",
    "print(\"Struktur der EEG-Daten:\", type(data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d7c968f-5afe-4db8-8f5d-5455580c8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionen der formatierten Daten: (100, 3, 400)\n",
      "Die Daten haben das erwartete Format.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Angenommen, Sie haben Ihre Daten bereits geladen:\n",
    "# ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(training_folder)\n",
    "\n",
    "# Konvertieren der EEG-Daten in das erforderliche Format\n",
    "def prepare_data(data, channels, time_steps=400):\n",
    "    num_records = len(data)\n",
    "    formatted_data = np.empty((num_records, 3, time_steps)) # [Anzahl der Beispiele, 3 Kanäle, Zeitpunkte]\n",
    "\n",
    "    for i in range(num_records):\n",
    "        montages, montage_data, _ = get_3montages(channels[i], data[i])\n",
    "        montage_data_resized = montage_data[:, :time_steps] if montage_data.shape[1] > time_steps else np.pad(montage_data, ((0,0), (0, time_steps - montage_data.shape[1])), 'constant')\n",
    "        formatted_data[i] = montage_data_resized\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "# Vorbereiten der Daten\n",
    "formatted_data = prepare_data(data, channels)\n",
    "\n",
    "# Überprüfen der Dimensionen der formatierten Daten\n",
    "print(\"Dimensionen der formatierten Daten:\", formatted_data.shape)\n",
    "\n",
    "# Stellen Sie sicher, dass die Dimensionen [num_records, 3, time_steps] sind\n",
    "expected_shape = (len(data), 3, 400)  # 400 ist ein Beispiel für time_steps\n",
    "if formatted_data.shape == expected_shape:\n",
    "    print(\"Die Daten haben das erwartete Format.\")\n",
    "else:\n",
    "    print(f\"Unerwartetes Format. Erwartet: {expected_shape}, Erhalten: {formatted_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53192664-6716-4bf1-bcf1-a989d9a5fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGNet(\n",
      "  (conv1): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6400, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_channels=3, time_steps=400):\n",
    "        super(EEGNet, self).__init__()\n",
    "        # 1D Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Anpassen der Feature-Map-Größe nach Pooling\n",
    "        reduced_size = time_steps // 4  # angenommen, zweimaliges Pooling halbiert die Größe jedes Mal\n",
    "        self.fc1 = nn.Linear(64 * reduced_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten der Ausgabe für die Linear Layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = EEGNet(num_channels=3, time_steps=400)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3ac71e-7d49-487c-9bce-04c890d7daa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_f1 = 0.0  # Initialisieren Sie den besten F1-Score mit 0\n",
    "best_model = None  # Variable zum Speichern des besten Modells\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validierung und Berechnung des F1-Scores\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.squeeze().round()\n",
    "            all_predictions.extend(predicted.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "\n",
    "    epoch_f1 = f1_score(all_labels, all_predictions)\n",
    "    if epoch_f1 > best_f1:\n",
    "        best_f1 = epoch_f1\n",
    "        best_model = model.state_dict()  # Speichern des besten Modells\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, F1-Score: {epoch_f1:.4f}')\n",
    "\n",
    "# Laden des besten Modells nach dem Training\n",
    "model.load_state_dict(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02bd3591-af42-476c-9261-1454cae2e2eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_model = model.state_dict()  # Initialisierung mit dem Anfangszustand des Modells\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())  # Stellen Sie sicher, dass beide eindimensional sind\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validierung und Berechnung des F1-Scores\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.squeeze().round()  # Squeeze und Round für binäre Klassifikation\n",
    "            all_predictions.extend(predicted.tolist())\n",
    "            all_labels.extend(labels.squeeze().tolist())  # Stellen Sie sicher, dass die Labels eindimensional sind\n",
    "\n",
    "    epoch_f1 = f1_score(all_labels, all_predictions)\n",
    "    if epoch_f1 > best_f1:\n",
    "        best_f1 = epoch_f1\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, F1-Score: {epoch_f1:.4f}')\n",
    "\n",
    "# Laden des besten Modells nach dem Training\n",
    "model.load_state_dict(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f89ce6-0b38-4395-9b3d-dd12d0fb02aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
